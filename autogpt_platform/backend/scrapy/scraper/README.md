ğŸ§  Werc AI-Enhanced Web Scraper â€“ README
Version: v1.4 â€“ Last Updated: 2025-03-22
Scrapes creative-industry websites (e.g. LBBOnline, D&AD) using hybrid scraping + Azure OpenAI for selector suggestions, validation, and role enrichment.

ğŸ“ Directory Structure
bash
Copy
Edit
backend/scrapy/
â”œâ”€â”€ mission_runner.py             # Main orchestrator
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ project_scraper.py        # Project data extractor
â”‚   â”œâ”€â”€ ai_enhancer.py            # Azure OpenAI integration
â”‚   â”œâ”€â”€ snapshot_analyzer.py      # Snapshot debugger
â”‚   â”œâ”€â”€ site_analyzer.py          # Infers page structure
â”‚   â”œâ”€â”€ domain_scanner.py         # Finds project links
â”‚   â”œâ”€â”€ company_scraper.py        # Entity extraction
â”‚   â”œâ”€â”€ validator.py              # Data completeness checks
â”‚   â””â”€â”€ fallback_mapping.json     # Maps role IDs to normalized roles
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py                 # .env + settings manager
â”‚   â””â”€â”€ testing.py                # AI test harness
â”œâ”€â”€ blob/uploader.py             # Uploads media to Azure Blob
â”œâ”€â”€ sql/db_writer.py             # Final DB writer
â”œâ”€â”€ snapshots/                   # HTML snapshots for debugging
â”œâ”€â”€ test_results/                # Output from test runs
âš™ï¸ Setup Instructions
ğŸ”§ Install Dependencies
bash
Copy
Edit
pip install rich==13.7.0 python-slugify==8.0.4 tqdm==4.66.2 python-dotenv==1.0.1
ğŸ“¦ Initialize Directory
bash
Copy
Edit
mkdir -p backend/scrapy/snapshots backend/scrapy/test_results
cp .env.example .env  # Then add Azure OpenAI API keys
ğŸ” Required .env Keys
dotenv
Copy
Edit
AZURE_OPENAI_API_KEY1=your-key
AZURE_OPENAI_ENDPOINT=https://wercopenai.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview
AZURE_OPENAI_4OM_ENDPOINT=https://wercopenai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2025-01-01-preview
ğŸš€ 6-Step Project Scraper Process
python
Copy
Edit
1. html = fetch_html_and_snapshot(url)
2. strategy = select_strategy(html, url)
3. data = extract_project_data(html, strategy, url, fallback_mapping)
4. missing = validate_scraped_data(data)
5. if missing: suggest_fixes_via_openai(html, url, missing)
6. return data
ğŸ’» Example Usage
ğŸ”¹ Basic Scrape
bash
Copy
Edit
python -m backend.scrapy.scraper.project_scraper https://lbbonline.com/work/132158 --output results.json
ğŸ”¹ Scrape with AI Enhancer
bash
Copy
Edit
python -m backend.scrapy.scraper.project_scraper https://lbbonline.com/work/132158 --output results.json --ai-model gpt-4o-mini
ğŸ”¹ Normalize Roles with Fallback
bash
Copy
Edit
python -m backend.scrapy.scraper.project_scraper https://lbbonline.com/work/132158 --normalize-roles
ğŸ§ª Snapshot Analyzer
ğŸ” Listing & Debugging
bash
Copy
Edit
python -m backend.scrapy.scraper.snapshot_analyzer list
python -m backend.scrapy.scraper.snapshot_analyzer analyze lbbonline_com__HASH.html
ğŸ”¬ Selector Testing
bash
Copy
Edit
python -m backend.scrapy.scraper.snapshot_analyzer analyze lbbonline_com__HASH.html --selector ".credit-entry"
ğŸ§  Generate Strategy
bash
Copy
Edit
python -m backend.scrapy.scraper.snapshot_analyzer strategy lbbonline_com__HASH.html --ai --output strategy.json
ğŸ§‘â€ğŸš€ Full Mission Execution
bash
Copy
Edit
python -m backend.scrapy.mission_runner "https://lbbonline.com/work?edition=international" --debug
Agents triggered based on site_analyzer output.

ğŸ¤– AI Features
1. Selector Suggestions
json
Copy
Edit
{
  "selectors": {
    "companies": ".credit-entry",
    "roles": ".role-name"
  },
  "explanations": {
    "companies": "Targets credit blocks",
    "roles": "Targets role titles"
  }
}
2. Role Normalization
json
Copy
Edit
{
  "12345": "Creative Director",
  "67890": "Director of Photography"
}
3. Full Strategy Generation
json
Copy
Edit
{
  "strategy": "lbbonline_v1",
  "selectors": {
    "title": "h1",
    "description": ".field--name-field-description",
    "credit_blocks": ".credit-entry",
    "company_name": ".company-name a"
  }
}
ğŸ§ª Testing
Snapshot Comparison
bash
Copy
Edit
python -m backend.scrapy.scraper.test_ai_enhanced --test-url https://lbbonline.com/work/132158
Generates logs and comparison between:

Default strategy
AI-enhanced recovery
âœ… Output Format
json
Copy
Edit
{
  "title": "Project Title",
  "client": "Brand Name",
  "date": "2025",
  "companies": [
    {
      "name": "Company A",
      "type": "Production",
      "credits": [
        {
          "person": { "name": "Jane Doe" },
          "role": "Creative Director"
        }
      ]
    }
  ],
  "meta": {
    "strategy": "lbbonline_v1",
    "credits_enriched": true
  }
}
ğŸ§  Future Roadmap
Agent reward system (scores per mission)
Interactive scraping strategy builder
Multi-agent replay debugging
Entity deduplication across domains
ğŸ› ï¸ Troubleshooting
Issue	Fix
ModuleNotFoundError	Ensure __init__.py files exist
ImportError	Run from root autogpt_platform/
Missing Roles	Use --normalize-roles or snapshot debugger
AI not responding	Check .env Azure key & endpoint
Invalid data	Use --debug to step through each phase
